{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#self learning chat bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c conda-forge newspaper3k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda update -n base -c defaults conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "import random\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get article url\n",
    "article=Article(\"https://www.mayoclinic.org/diseases-conditions/chronic-kidney-disease/symptoms-causes/syc-20354521\")\n",
    "article.download()\n",
    "article.parse()\n",
    "article.nlp()\n",
    "corpus=article.text\n",
    "\n",
    "#Print corpus/text\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "text=corpus\n",
    "sent_tokens=nltk.sent_tokenize(text) # convert text into list of sentences\n",
    "print(sent_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dictionary (key:value pair) to remove punctuations\n",
    "remove_punct_dict=dict( (ord(punct), None) for punct in string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(remove_punct_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to return a list of lemmatized lower case words after removing punctuations\n",
    "def LemNormalize(text):\n",
    "    return nltk.word_tokenize(text.lower())\n",
    "print(LemNormalize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keyword matching\n",
    "#greeting inputs\n",
    "GREETING_INPUTS=[\"hi\",\"hello\",\"hola\",\"greetings\",\"wassup\",\"hey\"]\n",
    "\n",
    "#greeting responses\n",
    "GREETING_RESPONSES=[\"howdy\",\"hi\",\"hey\",\"what's good\",\"hello\",\"hey there\"]\n",
    "\n",
    "#function to return a random greeting response to a user greeting\n",
    "def greeting(sentence):\n",
    "    #if user input is a greeting,then return a randomly chosen greeting response\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user response/query\n",
    "user_response=\"what is chronic kidney disease\"\n",
    "user_response=user_response.lower()\n",
    "print(user_response)\n",
    "\n",
    "# set the chatbot response to an empty string\n",
    "robo_response=''\n",
    "\n",
    "#append the user response to sentence list\n",
    "sent_tokens.append(user_response)\n",
    "\n",
    "#print sentence list after appending the user response\n",
    "print(sent_tokens)\n",
    "\n",
    "#create a tfidfvectorizer object\n",
    "TfidfVec=TfidfVectorizer(tokenizer=LemNormalize,stop_words='english')\n",
    "\n",
    "#convert  text to matrix of tf-idf features\n",
    "tfidf=TfidfVec.fit_transform(sent_tokens)\n",
    "\n",
    "print(tfidf)\n",
    "\n",
    "#get measure of similarity(similarity scores)\n",
    "vals=cosine_similarity(tfidf[-1],tfidf)\n",
    "\n",
    "#print similarity scores\n",
    "print(vals)\n",
    "\n",
    "#get the index of the most similar text/sentence to user response\n",
    "idx=vals.argsort()[0][-2]\n",
    "\n",
    "#reduce dimensionality of vals\n",
    "flat=vals.flatten()\n",
    "\n",
    "#sort the list in ascending order\n",
    "flat.sort()\n",
    "\n",
    "#get most similar score to users response\n",
    "score=flat[-2]\n",
    "\n",
    "#print similarity score\n",
    "print(score)\n",
    "\n",
    "#if the variable score is 0 then there is no text similar to users responsee\n",
    "if(score==0):\n",
    "    robo_response=robo_response+\"I apologize, idont understand\"\n",
    "else:\n",
    "    robo_response=robo_response+sent_tokens[idx]\n",
    "    \n",
    "#print chatbot response\n",
    "print(robo_response)\n",
    "sent_tokens.remove(user_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user response/query\n",
    "def response(user_response):\n",
    "    #user_response=\"what is chronic kidney disease\"\n",
    "    user_response=user_response.lower()\n",
    "    #print(user_response)\n",
    "\n",
    "    # set the chatbot response to an empty string\n",
    "    robo_response=''\n",
    "\n",
    "    #append the user response to sentence list\n",
    "    sent_tokens.append(user_response)\n",
    "\n",
    "    #print sentence list after appending the user response\n",
    "    #print(sent_tokens)\n",
    "\n",
    "    #create a tfidfvectorizer object\n",
    "    TfidfVec=TfidfVectorizer(tokenizer=LemNormalize,stop_words='english')\n",
    "\n",
    "    #convert  text to matrix of tf-idf features\n",
    "    tfidf=TfidfVec.fit_transform(sent_tokens)\n",
    "\n",
    "    #print(tfidf)\n",
    "\n",
    "    #get measure of similarity(similarity scores)\n",
    "    vals=cosine_similarity(tfidf[-1],tfidf)\n",
    "\n",
    "    #print similarity scores\n",
    "    #print(vals)\n",
    "\n",
    "    #get the index of the most similar text/sentence to user response\n",
    "    idx=vals.argsort()[0][-2]\n",
    "\n",
    "    #reduce dimensionality of vals\n",
    "    flat=vals.flatten()\n",
    "\n",
    "    #sort the list in ascending order\n",
    "    flat.sort()\n",
    "\n",
    "    #get most similar score to users response\n",
    "    score=flat[-2]\n",
    "\n",
    "    #print similarity score\n",
    "    #print(score)\n",
    "\n",
    "    #if the variable score is 0 then there is no text similar to users responsee\n",
    "    if(score==0):\n",
    "        robo_response=robo_response+\"I apologize, idont understand\"\n",
    "    else:\n",
    "        robo_response=robo_response+sent_tokens[idx]\n",
    "    \n",
    "    #print chatbot response\n",
    "    #print(robo_response)\n",
    "    \n",
    "    sent_tokens.remove(user_response)\n",
    "    return robo_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag=True\n",
    "print(\"DOCBot: I am Dr. Bot or DocBot i will answer your queries. if you want to exit type bye\")\n",
    "while(flag== True):\n",
    "    user_response=input()\n",
    "    user_response=user_response.lower()\n",
    "    if (user_response != \"bye\"):\n",
    "        if (user_response==\"thanks\" or user_response==\"thank you\"):\n",
    "            flag=false\n",
    "            print(\"DocBot: you are welcome\")\n",
    "        else:\n",
    "            if(greeting(user_response)!=None):\n",
    "                print(\"DocBot: \"+greeting(user_response))\n",
    "            else:\n",
    "                print(\"DocBot: \"+response(user_response))\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"DocBot: chat with you later\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
